{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czeQHAtWi23U",
        "outputId": "cdb2265b-7bf2-4969-c64c-b78bb8a47847"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Feb 28 17:12:37 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0             43W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import pickle\n",
        "from IPython.display import display, clear_output\n",
        "from matplotlib import animation\n",
        "from IPython import display as ipythondisplay\n",
        "import os\n",
        "\n",
        "is_ipython_env = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython_env:\n",
        "    from IPython.display import display, clear_output\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "\n",
        "compute_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "7jp6wX6Ai7gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_checkpoint(state, filename=\"checkpoint.pth\"):\n",
        "    torch.save(state, filename)\n",
        "\n",
        "def load_checkpoint(filename=\"checkpoint.pth\"):\n",
        "    if os.path.isfile(filename):\n",
        "        state = torch.load(filename)\n",
        "        print(\"Loaded checkpoint '{}'\" .format(filename))\n",
        "        return state\n",
        "    else:\n",
        "        print(\"No checkpoint found at '{}'\" .format(filename))\n",
        "        return None\n",
        "\n",
        "def display_rewards(show_final=False):\n",
        "    plt.figure(1)\n",
        "    plt.clf()\n",
        "    plt.title('Results' if show_final else 'Training Progress')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Total Reward')\n",
        "    plt.plot(torch.tensor(total_rewards, dtype=torch.float).numpy())\n",
        "    if len(total_rewards) >= 50:\n",
        "        rolling_mean = torch.tensor(total_rewards, dtype=torch.float).unfold(0, 50, 1).mean(1).view(-1)\n",
        "        rolling_mean = torch.cat((torch.full((49,), -21), rolling_mean))\n",
        "        plt.plot(rolling_mean.numpy())\n",
        "    plt.pause(0.001)\n",
        "    if is_ipython_env and not show_final:\n",
        "        display(plt.gcf())\n",
        "        clear_output(wait=True)\n",
        "    elif show_final:\n",
        "        display(plt.gcf())"
      ],
      "metadata": {
        "id": "3zqIWq25jEx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def refine_frame(frame):\n",
        "    frame = frame[6:189]\n",
        "    frame = frame[::2, ::2]\n",
        "    frame = frame.astype(np.float32) / 255.0\n",
        "    frame = np.transpose(frame, (2, 0, 1))\n",
        "    return torch.from_numpy(frame).to(compute_device)\n",
        "\n",
        "def assemble_state(frames):\n",
        "    state = torch.cat(tuple(frames), dim=0)\n",
        "    state = state.unsqueeze(0)\n",
        "    return state\n",
        "\n",
        "\n",
        "# Defining the convolutionlayer. Since we are stacking frames hence for three frames 3 frames and 3 RGB channels 9 is used\n",
        "class ConvDQN(nn.Module):\n",
        "    def __init__(self, height, width, action_count):\n",
        "        super(ConvDQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(9, 32, kernel_size=5, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "\n",
        "\n",
        "        def compute_conv_output_size(size, kernel_size=5, stride=2):\n",
        "            return (size - (kernel_size - 1) - 1) // stride + 1\n",
        "        conv_width = compute_conv_output_size(compute_conv_output_size(width))\n",
        "        conv_height = compute_conv_output_size(compute_conv_output_size(height))\n",
        "        linear_input_size = conv_width * conv_height * 32\n",
        "#         print(\"Expected input size to fc1:\", linear_input_size)\n",
        "        self.fc1 = nn.Linear(linear_input_size, 512)\n",
        "        self.fc2 = nn.Linear(512, action_count)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "#         print(\"Actual size before fc1:\", x.shape)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "def choose_action(state, eps_threshold):\n",
        "    global steps_taken\n",
        "    random_sample = random.random()\n",
        "    if random_sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            return strategy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[random.randrange(action_space_size)]], device=compute_device, dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        "class ExperienceReplay(object):\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def add(self, *args):\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample_batch(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "\n",
        "\n",
        "def refine_model():\n",
        "    if len(memory_bank) < batch_size:\n",
        "        return\n",
        "    sampled_transitions = memory_bank.sample_batch(batch_size)\n",
        "    batch = Transition(*zip(*sampled_transitions))\n",
        "\n",
        "    non_terminal_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=compute_device, dtype=torch.bool)\n",
        "    non_terminal_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    current_q_values = strategy_net(state_batch).gather(1, action_batch)\n",
        "    next_q_values = torch.zeros(batch_size, device=compute_device)\n",
        "    next_q_values[non_terminal_mask] = target_net(non_terminal_next_states).max(1)[0].detach()\n",
        "    expected_q_values = (next_q_values * discount_factor) + reward_batch\n",
        "\n",
        "    loss = nn.SmoothL1Loss()(current_q_values, expected_q_values.unsqueeze(1))\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n"
      ],
      "metadata": {
        "id": "QGmNH4Q_jJfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gym.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZLLtOakFjLRs",
        "outputId": "e96363c6-a578-48c1-a3cb-6b3805294f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.26.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gym[atari]\n",
        "!pip install autorom[accept-rom-license]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTGvD50ljcrc",
        "outputId": "0c2f9d77-4ff4-4e18-ec13-721bfca3897d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autorom[accept-rom-license]\n",
            "  Using cached AutoROM-0.6.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (8.1.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autorom[accept-rom-license]) (2.32.3)\n",
            "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license])\n",
            "  Using cached AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autorom[accept-rom-license]) (2025.1.31)\n",
            "Using cached AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=autorom_accept_rom_license-0.6.1-py3-none-any.whl size=446673 sha256=bc8ac87f37aabc9e20b375fc13de399e19f6bde7d8960f388c2833211224e65d\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/fc/c6/8aa657c0d2089982f2dabd110efc68c61eb49831fdb7397351\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom\n",
            "Successfully installed AutoROM.accept-rom-license-0.6.1 autorom-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Pong-v4\", render_mode=\"human\") # Pass render_mode to gym.make\n",
        "env.reset()\n",
        "initial_frame, _ = env.render() # Get initial frame using env.render\n",
        "initial_frame = refine_frame(initial_frame) # Process the initial frame\n",
        "_, frame_height, frame_width = initial_frame.shape\n",
        "\n",
        "frame_sequence = deque([initial_frame for _ in range(3)], maxlen=3)\n",
        "current_state = assemble_state(frame_sequence)\n",
        "_, _, frame_heaight, frame_width = current_state.shape\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "discount_factor = 0.995\n",
        "EPSILON_START = 1\n",
        "EPSILON_END = 0.01\n",
        "EPSILON_DECAY = 1500\n",
        "update_target_net_interval = 175\n",
        "learning_rate = 2e-5\n",
        "total_episodes = 40000\n",
        "steps_taken = 0\n",
        "\n",
        "action_space_size = env.action_space.n\n",
        "strategy_net = ConvDQN(frame_height, frame_width, action_space_size).to(compute_device)\n",
        "target_net = ConvDQN(frame_height, frame_width, action_space_size).to(compute_device)\n",
        "target_net.load_state_dict(strategy_net.state_dict())\n",
        "target_net.eval()\n",
        "optimizer = optim.AdamW(strategy_net.parameters(), lr=learning_rate)\n",
        "memory_bank = ExperienceReplay(100000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "xYX_3WvGjNYB",
        "outputId": "9ec11195-3733-467d-93d7-84d39ebbbc42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to initialize SDL",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-aedc4f5ab7df>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pong-v4\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"human\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Pass render_mode to gym.make\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minitial_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Get initial frame using env.render\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minitial_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefine_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_frame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Process the initial frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ale_py/env/gym.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, game, mode, difficulty, obs_type, frameskip, repeat_action_probability, full_action_space, max_num_frames_per_episode, render_mode)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Seed + Load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         self._action_set = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ale_py/env/gym.py\u001b[0m in \u001b[0;36mseed\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;34m\"https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             )\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadROM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_game\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_game_mode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to initialize SDL"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eW7outP6jPFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3KycL0JMmDUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[atari]\n",
        "import numpy as np\n",
        "import gym"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glWGbInOmDSB",
        "outputId": "9ed09f58-881d-4242-f29a-7b9a0fe953c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym[atari] in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym[atari]) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym[atari]) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym[atari]) (0.0.8)\n",
            "INFO: pip is looking at multiple versions of gym[atari] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gym[atari]\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ale-py~=0.8.0 (from gym[atari])\n",
            "  Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from ale-py~=0.8.0->gym[atari]) (6.5.2)\n",
            "Downloading ale_py-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827697 sha256=b6b92eea74b2ef8ebfa4b72322fa6b588c188d3e815bf9d44e627e699b4e1702\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/77/9e/9af5470201a0b0543937933ee99ba884cd237d2faefe8f4d37\n",
            "Successfully built gym\n",
            "Installing collected packages: gym, ale-py\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Attempting uninstall: ale-py\n",
            "    Found existing installation: ale-py 0.10.2\n",
            "    Uninstalling ale-py-0.10.2:\n",
            "      Successfully uninstalled ale-py-0.10.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires ale-py>=0.10.1, but you have ale-py 0.8.1 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ale-py-0.8.1 gym-0.26.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gym import wrappers\n",
        "from gym.wrappers import RecordVideo"
      ],
      "metadata": {
        "id": "qmF0lOGvmDPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Pong-v0\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "EWixOE8_mDML",
        "outputId": "ddd73558-dc91-40b4-9b8b-ab028233f268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Error",
          "evalue": "We're Unable to find the game \"Pong\". Note: Gym no longer distributes ROMs. If you own a license to use the necessary ROMs for research purposes you can download them via `pip install gym[accept-rom-license]`. Otherwise, you should try importing \"Pong\" via the command `ale-import-roms`. If you believe this is a mistake perhaps your copy of \"Pong\" is unsupported. To check if this is the case try providing the environment variable `PYTHONWARNINGS=default::ImportWarning:ale_py.roms`. For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b3dd88479669>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pong-v0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/gym/envs/registration.py\u001b[0m in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 640\u001b[0;31m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    641\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ale_py/env/gym.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, game, mode, difficulty, obs_type, frameskip, repeat_action_probability, full_action_space, max_num_frames_per_episode, render_mode)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# Seed + Load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         self._action_set = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ale_py/env/gym.py\u001b[0m in \u001b[0;36mseed\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_game\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             raise error.Error(\n\u001b[0m\u001b[1;32m    207\u001b[0m                 \u001b[0;34mf'We\\'re Unable to find the game \"{self._game}\". Note: Gym no longer distributes ROMs. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;34mf\"If you own a license to use the necessary ROMs for research purposes you can download them \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mError\u001b[0m: We're Unable to find the game \"Pong\". Note: Gym no longer distributes ROMs. If you own a license to use the necessary ROMs for research purposes you can download them via `pip install gym[accept-rom-license]`. Otherwise, you should try importing \"Pong\" via the command `ale-import-roms`. If you believe this is a mistake perhaps your copy of \"Pong\" is unsupported. To check if this is the case try providing the environment variable `PYTHONWARNINGS=default::ImportWarning:ale_py.roms`. For more information see: https://github.com/mgbellemare/Arcade-Learning-Environment#rom-management"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.action_space)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnIlyfyfmqAp",
        "outputId": "d28e08c8-c881-4c0e-f5db-4ad1306ede18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Discrete(6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.get_action_meanings())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txJ7w-plmrvM",
        "outputId": "fdd8cb61-1cdc-418e-af89-27a77276d2a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = RecordVideo(env, video_folder=\"./video\", episode_trigger=lambda episode_id: True)\n"
      ],
      "metadata": {
        "id": "0PEi2mhamuCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(env.observation_space)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvtMZS2umxID",
        "outputId": "6cefe756-e95e-486c-dcd3-35e25479e558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Box(0, 255, (210, 160, 3), uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create the environment with the desired render mode\n",
        "env = gym.make(\"Pong-v0\", render_mode=\"rgb_array\")\n",
        "\n",
        "env.seed(42)\n",
        "frame = env.reset()\n",
        "\n",
        "# Now calling render() returns an rgb_array frame\n",
        "random_frame = env.render()\n",
        "print(random_frame.shape)\n",
        "plt.imshow(random_frame)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "id": "yfXMGKbYnEg2",
        "outputId": "51514e48-6b6e-4f6d-d891-453d7b5747e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(210, 160, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def frame_preprocessing(observation_frame):\n",
        "    # Crop the frame.\n",
        "    observation_frame = observation_frame[35:195]\n",
        "    # Downsample the frame by a factor of 2.\n",
        "    observation_frame = observation_frame[::2, ::2, 0]\n",
        "    # Remove the background and apply other enhancements.\n",
        "    observation_frame[observation_frame == 144] = 0  # Erase the background (type 1).\n",
        "    observation_frame[observation_frame == 109] = 0  # Erase the background (type 2).\n",
        "    observation_frame[observation_frame != 0] = 1  # Set the items (rackets, ball) to 1.\n",
        "    # Return the preprocessed frame as a 1D floating-point array.\n",
        "    return observation_frame.astype(float)"
      ],
      "metadata": {
        "id": "Z12BnJx9nIq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed_random_frame = frame_preprocessing(random_frame)\n",
        "plt.imshow(preprocessed_random_frame, cmap=\"gray\")\n",
        "print(preprocessed_random_frame.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "43EP1K1cndby",
        "outputId": "af16c47f-dba4-4879-a007-3536cb939dca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80, 80)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.default_rng(seed=12288743)\n"
      ],
      "metadata": {
        "id": "oyUy8S23ngA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = 80 * 80\n"
      ],
      "metadata": {
        "id": "1x5Qumzrnj-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "H = 200\n"
      ],
      "metadata": {
        "id": "ZJb1c_MCnlTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = {}\n"
      ],
      "metadata": {
        "id": "QBZcSVzQnmn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model[\"W1\"] = rng.standard_normal(size=(H, D)) / np.sqrt(D)\n",
        "model[\"W2\"] = rng.standard_normal(size=H) / np.sqrt(H)\n"
      ],
      "metadata": {
        "id": "u6qkUmg5noYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_forward(x, model):\n",
        "    # Matrix-multiply the weights by the input in the one and only hidden layer.\n",
        "    h = np.dot(model[\"W1\"], x)\n",
        "    # Apply non-linearity with ReLU.\n",
        "    h[h < 0] = 0\n",
        "    # Calculate the \"dot\" product in the outer layer.\n",
        "    # The input for the sigmoid function is called logit.\n",
        "    logit = np.dot(model[\"W2\"], h)\n",
        "    # Apply the sigmoid function (non-linear activation).\n",
        "    p = sigmoid(logit)\n",
        "    # Return a log probability for the action 2 (\"move up\")\n",
        "    # and the hidden \"state\" that you need for backpropagation.\n",
        "    return p, h"
      ],
      "metadata": {
        "id": "eG-Bf0GonqXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1.0 / (1.0 + np.exp(-x))"
      ],
      "metadata": {
        "id": "zti0sb0onsO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_backward(eph, epdlogp, model):\n",
        "    dW2 = np.dot(eph.T, epdlogp).ravel()\n",
        "    dh = np.outer(epdlogp, model[\"W2\"])\n",
        "    dh[eph <= 0] = 0\n",
        "    dW1 = np.dot(dh.T, epx)\n",
        "    # Return new \"optimized\" weights for the policy network.\n",
        "    return {\"W1\": dW1, \"W2\": dW2}"
      ],
      "metadata": {
        "id": "XneMk7ZCnu4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# All preprocessed observations for the episode.\n",
        "xs = []\n",
        "# All hidden \"states\" (from the network) for the episode.\n",
        "hs = []\n",
        "# All gradients of probability actions\n",
        "# (with respect to observations) for the episode.\n",
        "dlogps = []\n",
        "# All rewards for the episode.\n",
        "drs = []"
      ],
      "metadata": {
        "id": "OviXXbtenwen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decay_rate = 0.99\n"
      ],
      "metadata": {
        "id": "izub497dny0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grad_buffer = {k: np.zeros_like(v) for k, v in model.items()}\n"
      ],
      "metadata": {
        "id": "lSQiFqtzn1FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rmsprop_cache = {k: np.zeros_like(v) for k, v in model.items()}\n"
      ],
      "metadata": {
        "id": "dyWDOjmvn2Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.99\n",
        "\n",
        "\n",
        "def discount_rewards(r, gamma):\n",
        "    discounted_r = np.zeros_like(r)\n",
        "    running_add = 0\n",
        "    # From the last reward to the first...\n",
        "    for t in reversed(range(0, r.size)):\n",
        "        # ...reset the reward sum\n",
        "        if r[t] != 0:\n",
        "            running_add = 0\n",
        "        # ...compute the discounted reward\n",
        "        running_add = running_add * gamma + r[t]\n",
        "        discounted_r[t] = running_add\n",
        "    return discounted_r"
      ],
      "metadata": {
        "id": "Ypn-ypeEn3mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_episodes = 3\n"
      ],
      "metadata": {
        "id": "xnZzqvxbn5nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 3\n",
        "learning_rate = 1e-4"
      ],
      "metadata": {
        "id": "2HKs_d-an8CC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "render = False\n",
        "observation = env.reset()\n"
      ],
      "metadata": {
        "id": "K2ed9yw6n9xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prev_x = None\n",
        "running_reward = None\n",
        "reward_sum = 0\n",
        "episode_number = 0\n",
        "\n",
        "\n",
        "def update_input(prev_x, cur_x, D):\n",
        "    if prev_x is not None:\n",
        "        x = cur_x - prev_x\n",
        "    else:\n",
        "        x = np.zeros(D)\n",
        "    return x"
      ],
      "metadata": {
        "id": "dbYk6igQoDg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize environment and variables outside the loop\n",
        "observation, info = env.reset()\n",
        "prev_x = None\n",
        "episode_number = 0\n",
        "reward_sum = 0\n",
        "\n",
        "while episode_number < max_episodes:\n",
        "    if render:\n",
        "        env.render()\n",
        "\n",
        "    # Preprocess current frame\n",
        "    cur_x = frame_preprocessing(observation).ravel()\n",
        "\n",
        "    # For the first frame, you might want to set prev_x = cur_x\n",
        "    if prev_x is None:\n",
        "        prev_x = cur_x\n",
        "\n",
        "    # Prepare input for the policy network\n",
        "    x = update_input(prev_x, cur_x, D)\n",
        "    prev_x = cur_x\n",
        "\n",
        "    # Forward pass through the policy network\n",
        "    aprob, h = policy_forward(x, model)\n",
        "\n",
        "    # Choose action based on probability\n",
        "    action = 2 if rng.uniform() < aprob else 3\n",
        "\n",
        "    # Save intermediate variables for backpropagation\n",
        "    xs.append(x)\n",
        "    hs.append(h)\n",
        "    y = 1 if action == 2 else 0  # target label\n",
        "    dlogps.append(y - aprob)\n",
        "\n",
        "    # Take action in the environment\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    done = terminated or truncated\n",
        "\n",
        "    # Accumulate reward and store it\n",
        "    reward_sum += reward\n",
        "    drs.append(reward)\n",
        "\n",
        "    # If the episode has finished\n",
        "    if done:\n",
        "        episode_number += 1\n",
        "\n",
        "        # Stack episode data\n",
        "        epx = np.vstack(xs)\n",
        "        eph = np.vstack(hs)\n",
        "        epdlogp = np.vstack(dlogps)\n",
        "        epr = np.vstack(drs)\n",
        "\n",
        "        # Reset episode buffers\n",
        "        xs, hs, dlogps, drs = [], [], [], []\n",
        "\n",
        "        # Discount and normalize rewards\n",
        "        discounted_epr = discount_rewards(epr, gamma)\n",
        "        discounted_epr -= np.mean(discounted_epr)\n",
        "        discounted_epr /= np.std(discounted_epr)\n",
        "\n",
        "        # Ensure epdlogp and discounted_epr have the same number of rows\n",
        "        min_len = min(len(epdlogp), len(discounted_epr))\n",
        "        epdlogp = epdlogp[:min_len]\n",
        "        discounted_epr = discounted_epr[:min_len]\n",
        "\n",
        "        # Multiply gradients by the advantage\n",
        "        epdlogp *= discounted_epr\n",
        "\n",
        "        # Backpropagation and gradient accumulation\n",
        "        grad = policy_backward(eph, epdlogp, model)\n",
        "        for k in model:\n",
        "            grad_buffer[k] += grad[k]\n",
        "\n",
        "        # Update parameters every batch_size episodes\n",
        "        if episode_number % batch_size == 0:\n",
        "            for k, v in model.items():\n",
        "                g = grad_buffer[k]\n",
        "                rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g ** 2\n",
        "                model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n",
        "                grad_buffer[k] = np.zeros_like(v)\n",
        "\n",
        "        # Update running reward and print results\n",
        "        running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n",
        "        print(\"Resetting the Pong environment. Episode total reward: {} Running mean: {}\".format(reward_sum, running_reward))\n",
        "\n",
        "        # Reset the environment and variables for the next episode\n",
        "        observation, info = env.reset()\n",
        "        prev_x = None\n",
        "        reward_sum = 0\n",
        "\n",
        "    # Optionally print when a non-zero reward is received\n",
        "    if reward != 0:\n",
        "        print(\"Episode {}: Game finished. Reward: {}...\".format(episode_number, reward) + (\"\" if reward == -1 else \" POSITIVE REWARD!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_FFOsXjoMgU",
        "outputId": "304c031d-f1de-49d1-ede6-194e074f43f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: 1.0... POSITIVE REWARD!\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: 1.0... POSITIVE REWARD!\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Episode 0: Game finished. Reward: -1.0...\n",
            "Resetting the Pong environment. Episode total reward: -19.0 Running mean: -20.9602\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Episode 1: Game finished. Reward: -1.0...\n",
            "Resetting the Pong environment. Episode total reward: -21.0 Running mean: -20.960598\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Episode 2: Game finished. Reward: -1.0...\n",
            "Resetting the Pong environment. Episode total reward: -21.0 Running mean: -20.960992020000003\n",
            "Episode 3: Game finished. Reward: -1.0...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Xvfb and X11 dependencies.\n",
        "!apt-get install -y xvfb x11-utils > /dev/null 2>&1\n",
        "# To work with videos, install FFmpeg.\n",
        "!apt-get install -y ffmpeg > /dev/null 2>&1\n",
        "# Install PyVirtualDisplay for visual feedback and other libraries/dependencies.\n",
        "!pip install pyvirtualdisplay PyOpenGL PyOpenGL-accelerate > /dev/null 2>&1"
      ],
      "metadata": {
        "id": "s-SToundoO79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the virtual display module.\n",
        "from pyvirtualdisplay import Display\n",
        "# Import ipythondisplay and HTML from IPython for image and video rendering.\n",
        "from IPython import display as ipythondisplay\n",
        "from IPython.display import HTML\n",
        "\n",
        "# Initialize the virtual buffer at 400x300 (adjustable size).\n",
        "# With Xvfb, you should set `visible=False`.\n",
        "display = Display(visible=False, size=(400, 300))\n",
        "display.start()\n",
        "\n",
        "# Check that no display is present.\n",
        "# If no displays are present, the expected output is `:0`.\n",
        "!echo $DISPLAY\n",
        "\n",
        "# Define a helper function to display videos in Jupyter notebooks:.\n",
        "# (Source: https://star-ai.github.io/Rendering-OpenAi-Gym-in-Colaboratory/)\n",
        "\n",
        "import sys\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "\n",
        "def show_any_video(mp4video=0):\n",
        "    mp4list = glob.glob('video/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[mp4video]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay\n",
        "                                            loop controls style=\"height: 400px;\">\n",
        "                                            <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "                                            </video>'''.format(encoded.decode('ascii'))))\n",
        "\n",
        "    else:\n",
        "        print('Could not find the video!')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7LE_iqQ7_WE",
        "outputId": "cb10dcb4-e530-4203-a400-b464b15883d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_any_video(-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fjhPmyW8Fbl",
        "outputId": "78a9ea71-16f8-4c78-d63d-a2913b8ec2c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not find the video!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8mpdQTU08Ft2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}